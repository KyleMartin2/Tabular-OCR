{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301e1087",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "614f0eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "from io import BytesIO\n",
    "from google.cloud import vision\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "from pdf2image import convert_from_path\n",
    "import numpy as np\n",
    "from operator import contains\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf8167",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebe7551",
   "metadata": {},
   "source": [
    "#### Convert PDF to JPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4766c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_jpg(pdf_name):\n",
    "    img = convert_from_path(\"images/{name}.pdf\".format(name=pdf_name),\n",
    "                           fmt=\"jpeg\")\n",
    "    \n",
    "    for pg_num, page in enumerate(img):\n",
    "        page.save(\"temp/{name}_{pg_num}.jpg\".format(name=pdf_name, pg_num=pg_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689213fe",
   "metadata": {},
   "source": [
    "#### Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe9bafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify Image\n",
    "to_jpg('table')\n",
    "\n",
    "#save jpg to temp folder\n",
    "img = cv2.imread(\"temp/table_0.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "#grey scale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imwrite(\"temp/index_gray.png\", gray)\n",
    "\n",
    "#blur\n",
    "blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "cv2.imwrite(\"temp/index_blur.png\", blur)\n",
    "\n",
    "#thresh\n",
    "thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 21, 4)\n",
    "cv2.imwrite(\"temp/thresh.png\", thresh)\n",
    "\n",
    "#kernal\n",
    "kernal = cv2.getStructuringElement(cv2.MORPH_RECT, (6, 6))\n",
    "cv2.imwrite(\"temp/kernal.png\", kernal)\n",
    "\n",
    "#dilate\n",
    "dilate = cv2.dilate(thresh, kernal, iterations = 1)\n",
    "cv2.imwrite(\"temp/dilate.png\", dilate)\n",
    "\n",
    "#contours\n",
    "cnts = cv2.findContours(dilate, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "cnts = sorted(cnts, key=lambda x: cv2.boundingRect(x)[0])\n",
    "\n",
    "#bounding boxes\n",
    "boxes_area = []\n",
    "boxes_centroid = []\n",
    "boxes_roi = []\n",
    "boxes_data = []\n",
    "\n",
    "for c in cnts:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    if h > 45 and w > 90: #these values may have to be adjusted depending on the input image\n",
    "        box_h = tuple(range(y, y+h))\n",
    "        box_w = tuple(range(x, x+w))\n",
    "        \n",
    "        box_area = (box_w, box_h)\n",
    "        box_centroid = (x+w/2, y+h/2)\n",
    "        box_roi = img[y:y+h, x:x+w]\n",
    "        box_data = (box_area, box_centroid, box_roi)\n",
    "        \n",
    "        boxes_area.append(box_area)\n",
    "        boxes_centroid.append(box_centroid)\n",
    "        boxes_roi.append(box_roi)\n",
    "        boxes_data.append(box_data)\n",
    "        \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(36,255,12),2)\n",
    "\n",
    "cv2.imwrite(\"temp/bbox.png\", img)\n",
    "\n",
    "\n",
    "#sort tables\n",
    "def sort_tables(area, boxes_centroid):\n",
    "    \n",
    "    temp_table = []\n",
    "    for centroid in boxes_centroid:\n",
    "        if all(map(contains, area, centroid)):\n",
    "            temp_table.append(centroid)\n",
    "    print(temp_table)\n",
    "    print(len(temp_table))\n",
    "    return sorted(temp_table)\n",
    "    \n",
    "tables = []     \n",
    "for area in boxes_area:\n",
    "    if len(sort_tables(area, boxes_centroid)) > 1:\n",
    "        tables.append(sort_tables(area, boxes_centroid))  \n",
    "                \n",
    "tables_data = []\n",
    "for table in tables:\n",
    "    temp_table = []\n",
    "    for centroid in table:\n",
    "        for box_data in boxes_data:\n",
    "            if centroid == box_data[1]:\n",
    "                temp_table.append(box_data)\n",
    "    tables_data.append(temp_table)\n",
    "    \n",
    "#draw points\n",
    "def draw_circle(points):\n",
    "    for point in points:\n",
    "        x = int(point[0])\n",
    "        y = int(point[1])\n",
    "        cv2.circle(img, (x,y), radius=10, color=(0, 0, 255), thickness=-1)\n",
    "    return cv2.imwrite(\"temp/points.png\", img)\n",
    "\n",
    "#thresh cells\n",
    "thresh_boxes = []\n",
    "for box in boxes_roi:\n",
    "    temp_box = box.copy()\n",
    "    temp_box[:,:,1] = np.zeros([temp_box.shape[0], temp_box.shape[1]]) #removes green- sets all values in green ch. to 0\n",
    "    temp_box = cv2.cvtColor(temp_box, cv2.COLOR_BGR2GRAY) #makes img greyscale\n",
    "    temp_box = cv2.adaptiveThreshold(temp_box, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 4)\n",
    "    thresh_boxes.append(temp_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23d5c7e",
   "metadata": {},
   "source": [
    "## OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de236495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#service account key\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'ServiceAccountToken.json'\n",
    "\n",
    "#definitions\n",
    "image_folder_dir = os.getcwd() + \"\\images\"\n",
    "image_filenames = os.listdir(image_folder_dir)\n",
    "\n",
    "def image_paths(image_filenames, image_folder_dir):\n",
    "    \n",
    "    image_paths = []\n",
    "    \n",
    "    for image_filename in image_filenames:\n",
    "        image_paths.append(os.path.join(image_folder_dir, image_filename))\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "paths = image_paths(image_filenames, image_folder_dir)\n",
    "\n",
    "#functions\n",
    "def detect_document(path):\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "            content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.document_text_detection(image=image)\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "def document_text(document):\n",
    "    \n",
    "    docText = document.full_text_annotation.text\n",
    "    \n",
    "    return docText\n",
    "\n",
    "\n",
    "def document_conf(document):\n",
    "    \n",
    "     for page in document.full_text_annotation.pages:\n",
    "            \n",
    "            for block in page.blocks:\n",
    "                print('\\nBlock confidence: {}\\n'.format(block.confidence))\n",
    "\n",
    "                for paragraph in block.paragraphs:\n",
    "                    print('Paragraph confidence: {}'.format(\n",
    "                        paragraph.confidence))\n",
    "\n",
    "                    for word in paragraph.words:\n",
    "                        word_text = ''.join([\n",
    "                            symbol.text for symbol in word.symbols\n",
    "                        ])\n",
    "                        print('Word text: {} (confidence: {})'.format(\n",
    "                            word_text, word.confidence))\n",
    "\n",
    "                        for symbol in word.symbols:\n",
    "                            print('\\tSymbol: {} (confidence: {})'.format(\n",
    "                                symbol.text, symbol.confidence))\n",
    "\n",
    "                            \n",
    "def drawVertices(image_path, word_attributes):\n",
    "    \n",
    "    image_file = image_path.encode('utf_8') #convert str to byte\n",
    "\n",
    "    pillow_img = Image.open(image_file)\n",
    "    \n",
    "    draw = ImageDraw.Draw(pillow_img)\n",
    "    \n",
    "    for word in word_attributes:\n",
    "        \n",
    "        word_conf = word_attributes.get(word)[0]\n",
    "        vertices = word_attributes.get(word)[1]\n",
    "        \n",
    "        if word_conf >= 0.9:\n",
    "            color = '#00ff00' #green\n",
    "        elif word_conf >= 0.8:\n",
    "            color = '#ffff00' #yellow\n",
    "        else:\n",
    "            color = '#ff0000' #red\n",
    "    \n",
    "        for i in range(len(vertices) - 1):\n",
    "            draw.line(((vertices[i].x, vertices[i].y), \n",
    "                     (vertices[i + 1].x, vertices[i + 1].y)),\n",
    "                     fill = color, \n",
    "                     width = 3\n",
    "                     )\n",
    "        draw.line(((vertices[len(vertices) - 1].x, vertices[len(vertices) - 1].y),\n",
    "                  (vertices[0].x, vertices[0].y)),\n",
    "                   fill = color,\n",
    "                   width = 3\n",
    "                   )\n",
    "        \n",
    "    pillow_img.show()\n",
    "\n",
    "def word_attributes(document):\n",
    "    \n",
    "    word_attributes = {}\n",
    "    \n",
    "    for page in document.full_text_annotation.pages:\n",
    "            \n",
    "            for block in page.blocks:\n",
    "\n",
    "                for paragraph in block.paragraphs:\n",
    "\n",
    "                    for word in paragraph.words:\n",
    "                        word_text = ''.join([\n",
    "                            symbol.text for symbol in word.symbols\n",
    "                        ])\n",
    "                        \n",
    "                        word_attributes[word_text] = (word.confidence, word.bounding_box.vertices)\n",
    "    \n",
    "    return word_attributes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "googleAPI",
   "language": "python",
   "name": "googleapi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
